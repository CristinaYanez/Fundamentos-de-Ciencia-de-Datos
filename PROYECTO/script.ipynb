{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a8cefe9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Proyecto Fundamentos de Ciencia de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59506de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "\n",
    "# Base de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# K medias \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import silhouette_score\n",
    "# predicción\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "# guardar los modelos\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de datos\n",
    "accounts=pd.read_csv('archive/accounts.csv')\n",
    "products=pd.read_csv('archive/products.csv')\n",
    "sales=pd.read_csv('archive/sales_pipeline.csv')\n",
    "team=pd.read_csv('archive/sales_teams.csv')\n",
    "done_deals=sales[sales['deal_stage']=='Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df = sales.merge(team, on='sales_agent') \n",
    "df = df[~df['account'].isna()]  \n",
    "df = df.merge(accounts,on='account') \n",
    "df['subsidiary_of']  = df['subsidiary_of'].fillna('')\n",
    "df['product']=df['product'].str.replace('GTXPro','GTX Pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bdbc3d",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e108969b",
   "metadata": {},
   "source": [
    "Análisis de una variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cce6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analisis de ventas (en dataframe sale):\n",
    "\n",
    "#close_value: distribucion de ventas cerradas por valor de cierre (solo done deals) ((histograma con 12 bins))\n",
    "counts, bin_edges = np.histogram(done_deals['close_value'], bins=12)\n",
    "bin_labels = [f\"{round(start)} - {round(end)}\" for start, end in zip(bin_edges[:-1], bin_edges[1:])]\n",
    "hist_df_canvas = pd.DataFrame({ 'bin': bin_labels, 'count': counts})\n",
    "hist_df_canvas.to_csv('1v_close_value.csv',index=False)\n",
    "#deal_stage: distribucion de las oportunidades ((pie chart))\n",
    "sales['deal_stage'].value_counts().to_csv('1v_deal_stage.csv')\n",
    "#sales_agent: distribucion de ventas cerradas por agente (solo done deals) #top 10 agents en vol de ventas ((bar chart))\n",
    "done_deals['sales_agent'].value_counts()[:10].to_csv('1v_sales_agent.csv')\n",
    "#product: distribucion de ventas cerradas por producto (solo done deals) ((horizontal chart))\n",
    "done_deals['product'].value_counts().to_csv('1v_product.csv')\n",
    "#account: distribucion de clientes con los que se hizo negocio (solo done deals) #top 10 clients en vol de ventas ((bar chart))\n",
    "done_deals['account'].value_counts()[:10].to_csv('1v_account.csv')\n",
    "#close_date: distribucion de ventas cerradas por fecha (solo done deals) ((line chart))\n",
    "done_deals['close_date'].str[:7].value_counts().to_csv('1v_close_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisis de clientes (en dataframe accounts):\n",
    "accounts[['account','revenue','employees']].to_csv('1v_histograms.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ea7c6",
   "metadata": {},
   "source": [
    "Análisis de dos variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04201af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sobre ventas  \n",
    "\n",
    "# distribucion del close_value para ventas cerradas por agente y producto \n",
    "done_deals1=done_deals.copy()\n",
    "done_deals1.loc[:,'product'] = done_deals1['product'].astype('category').cat.codes\n",
    "done_deals1.loc[:,'sales_agent'] = done_deals1['sales_agent'].astype('category').cat.codes\n",
    "g=sns.pairplot(done_deals1[['sales_agent','close_value','product']],\n",
    "             plot_kws={\"color\": \"#4283E6F6\", \"edgecolor\": \"none\"},     \n",
    "            diag_kws={\"color\": \"#37BA6BF6\", \"edgecolor\": \"gray\"},)\n",
    "sns.set(style=\"white\", rc={\"axes.facecolor\": \"#f2f1ec\", \"figure.facecolor\": \"#f2f1ec\"})\n",
    "plt.show()\n",
    "\n",
    "# sobre ventas y empresas\n",
    "\n",
    "# distribucion de close_value por sector economico, employees y revenue\n",
    "df1=df.copy()\n",
    "df1=df1[df1['deal_stage']=='Won']  \n",
    "df1.loc[:,'sector'] = df1['sector'].astype('category').cat.codes\n",
    "g=sns.pairplot(df1[['sector', 'revenue','close_value']],\n",
    "             plot_kws={\"color\": \"#558DC2F6\", \"edgecolor\": \"none\"},     \n",
    "            diag_kws={\"color\": \"#8A1DACF6\", \"edgecolor\": \"gray\"} ) \n",
    "\n",
    "# Ajustar cada eje\n",
    "# for ax in g.axes.flatten():\n",
    "#     if ax is not None:\n",
    "#         ax.set_facecolor('#F2F1EC')  # fondo del subgráfico\n",
    "#         for spine in ax.spines.values():\n",
    "#             spine.set_visible(False)  # quitar bordes\n",
    "#         ax.set_xlabel(\"\")            # quitar etiquetas\n",
    "#         ax.set_ylabel(\"\")\n",
    "#         ax.set_xticks([])           # quitar ticks\n",
    "#         ax.set_yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planteamiento del problema\n",
    "# ¿Qué meta-data se puede generar? aqui marcar los objetivos, la hoja de ruta del trabajo (basicamente lo que hicimos con Marco)\n",
    "# Se quiere evaluar el desempeño de los agentes de ventas, de modo que, dada la informacion de un nuevo cliente podamos asignar al agente que le atienda de manera óptima:\n",
    "# en terminos de: monto más alto de la venta, mayor experiencia del agente con ese tipo de clientes, etc. Por esto, tambien se busca clasificar a los clientes en clusters de acuerdo a sus características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ba24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesamiento de datos\n",
    "\n",
    "df['engage_date']=pd.to_datetime(df['engage_date'])\n",
    "df['close_date']=pd.to_datetime(df['close_date'])\n",
    "df['close_value'] = df['close_value'].fillna(0)   \n",
    "df=df.merge(products,how='left',on='product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56175bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar un modelo de clasificación o segmentacion de agentes (regresion logistica, k-medias) \n",
    "\n",
    "# kmeans (mejor parámetro)\n",
    "categorical_cols = ['sector', 'office_location', 'subsidiary_of']\n",
    "numeric_features = ['year_established', 'revenue', 'employees']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])\n",
    "X_processed = preprocessor.fit_transform(accounts) \n",
    "k_values = range(2, 11)\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_processed)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_processed, kmeans.labels_))\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Método del codo\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.title('Método del Codo')\n",
    "plt.xlabel('Número de Clústers')\n",
    "plt.ylabel('Inercia')\n",
    "\n",
    "# Índice de silueta\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_values, silhouette_scores, marker='o')\n",
    "plt.title('Índice de Silueta')\n",
    "plt.xlabel('Número de Clústers')\n",
    "plt.ylabel('Score de Silueta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a436c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K medias en la tabla de clientes\n",
    "\n",
    "categorical_cols = ['sector', 'office_location', ] \n",
    "numeric_features=['year_established','revenue', 'employees'] \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('kmeans', KMeans(n_clusters=4, random_state=42))\n",
    "])\n",
    "pipeline.fit(accounts)\n",
    "accounts['Clúster'] = pipeline.named_steps['kmeans'].labels_ \n",
    "sns.set(style=\"white\", rc={\"axes.facecolor\": \"#f2f1ec\", \"figure.facecolor\": \"#f2f1ec\"})\n",
    "g = sns.pairplot(\n",
    "    accounts,\n",
    "    hue='Clúster',          \n",
    "    palette='tab10',        \n",
    "    diag_kind='kde',        \n",
    ")\n",
    "for ax in g.axes.flatten():\n",
    "    if ax is not None:\n",
    "        ax.set_facecolor('#F2F1EC')  \n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)  \n",
    "        ax.set_xlabel(\"\")            \n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xticks([])           \n",
    "        ax.set_yticks([])\n",
    "    \n",
    "accounts['Clúster'].value_counts().to_csv('kmeans.csv')\n",
    "joblib.dump(pipeline, 'kmeans_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica con PCA\n",
    " \n",
    "features_transformed = pipeline.named_steps['preprocessor'].transform(accounts)\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(features_transformed)\n",
    "plot_df = pd.DataFrame(components, columns=['CP1', 'CP2'])\n",
    "plot_df['cluster'] = accounts['Clúster'].astype(str)\n",
    "plot_df['account'] = accounts['account']\n",
    "plot_df['revenue'] = accounts['revenue']\n",
    "plot_df['employees'] = accounts['employees']\n",
    "fig = px.scatter(\n",
    "    plot_df, x='CP1', y='CP2', color='cluster',\n",
    "    labels={'cluster': 'Clúster'},)\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='#f2f1ec',\n",
    "    paper_bgcolor='#f2f1ec',\n",
    "    legend_title_text='Clúster',\n",
    ")\n",
    "fig.update_layout(width=500, height=500)\n",
    "fig.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementar un modelo de predicción (xgboost, random forest, regresion lineal) para predecir performance futuro\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba.\n",
    "# realizar validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7722fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesamiento de datos para el modelo\n",
    "\n",
    "df=df[df['deal_stage']=='Won']\n",
    "df=df.merge(accounts[['account','Clúster']], on='account', how='left')\n",
    "model_df=df[[ 'sales_agent', 'product', 'engage_date', 'close_date', 'close_value', 'manager', 'regional_office', 'series', 'sales_price', 'Clúster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a428b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar diferentes modelos\n",
    "\n",
    "model_df=df[[ 'sales_agent', 'product',  'engage_date', 'close_date', 'close_value', 'manager', 'regional_office', 'series', 'sales_price', 'Clúster',  ]]\n",
    "categorical_features = ['sales_agent', 'product', 'manager', 'regional_office', 'series', 'Clúster']\n",
    "numerical_features = ['sales_price']\n",
    "\n",
    "X = model_df[categorical_features + numerical_features]\n",
    "y = model_df['close_value']\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('num', SimpleImputer(strategy='mean'), numerical_features)\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "models = {\n",
    "    'RandomForest': GridSearchCV(\n",
    "        Pipeline([('preprocessor', preprocessor), ('model', RandomForestRegressor())]),\n",
    "        param_grid={'model__n_estimators': [100, 200], 'model__max_depth': [None, 10, 20]},\n",
    "        cv=5\n",
    "    ),\n",
    "    'XGBoost': GridSearchCV(\n",
    "        Pipeline([('preprocessor', preprocessor), ('model', XGBRegressor(objective='reg:squarederror'))]),\n",
    "        param_grid={'model__n_estimators': [100, 200], 'model__max_depth': [3, 6]},\n",
    "        cv=5\n",
    "    ),\n",
    "    'LinearRegression': GridSearchCV(\n",
    "        Pipeline([('preprocessor', preprocessor), ('model', LinearRegression())]),\n",
    "        param_grid={},\n",
    "        cv=5\n",
    "    )\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        'Best Params': model.best_params_,\n",
    "        'MSE': mse,\n",
    "        'R2': r2\n",
    "    }\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    print(f\"  Mejores parámetros: {metrics['Best Params']}\")\n",
    "    print(f\"  Error cuadrático medio (MSE): {metrics['MSE']:.2f}\")\n",
    "    print(f\"  Coeficiente de determinación (R2): {metrics['R2']:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Random Forest con mejores parámetros \n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "joblib.dump(rf_pipeline, 'random_forest_pipeline.pkl')\n",
    "\n",
    "# Importancia de variables\n",
    "feature_names = rf_pipeline.named_steps['preprocessor'].transformers_[0][1].get_feature_names_out(categorical_features).tolist()\n",
    "feature_names += numerical_features\n",
    "importances = rf_pipeline.named_steps['model'].feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.barh(importance_df['Feature'][:8], importance_df['Importance'][:8])\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Importancia de las variables - Random Forest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('feature_importance_rf.png')\n",
    "plt.show()\n",
    "# Predicciones\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "comparison_df = pd.DataFrame({'Real': y_test.values, 'Predicho': y_pred})\n",
    "comparison_df[:201].to_csv('predicciones_rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusión\n",
    "# responder al problema de a quién le doy el incentivo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
